---
date: "2024-09-21T17:17:41+03:00"
description: ""
id: 8nrz4spinaeo5317xot4w74
publish: true
title: Linear Regression
updated: 1727622124674
---

<https://ru.wikipedia.org/wiki/Метод_наименьших_квадратов>

<https://en.wikipedia.org/wiki/Residual_sum_of_squares>

## Simple Linear Regression

Функция, описывающая зависимость целевой переменной от 1 параметра.

$$y = a_0 + a_1x + \alpha$$

Функция, которая пытается оценить значения целевой переменной на основе параметра.

$$\hat{Y}(x) = a_0 + a_1x$$

Получаем значение ошибки при оценке значения целевой переменной.

$$\alpha = y - \hat{y}$$

Для рассчета линейной регрессии требуется выбрать функцию потерь, при помощи которой будет улучшаться функция предсказания. 

Идея заключается в том, чтобы минимизировать функцию потерь на любом входном наборе параметров. 
То есть, чтобы улучшить функцию предсказания, требуется подобрать такие коэффициенты $a_0$ и $a_1$, при которых функия потерь будет показывать минимальные значения на любых входных данных.

Лучше всего брать функцию [[organize.resource.data-mining.mse|mse]], поскольку она сильно штрафует за ошибки. То есть даже при небольшой ошибке в предсказании, мы получаем большое значение функции потерь.

$$MSE (Mean Square Error)  = \frac{\sum_{i=1}^n{\left(Y - \hat{Y}\right)^2}}{n} \rArr min$$

Раскрываем $\hat{Y}(x)$ в формуле.

$$MSE (Mean Square Error)  = \frac{\sum_{i=1}^n{\left(Y_i - a_0 - a_1x_i\right)^2}}{n} \rArr min$$

Для минимизации функции потерь требуется найти ее градиент и двигаться в противоположном ему направлении. 

Используем [[organize.resource.data-mining.nabla|nabla]], по переменным $a_0$ и $a_1$, чтобы найти градиент.

$$\nabla MSE = \left(\frac{\sum_{i=1}^n{2\left(Y_i - a_0 - a_1x_i\right)(-1)}}{n}, \frac{\sum_{i=1}^n{2\left(Y_i - a_0 - a_1x_i\right)(-x_i)}}{n} \right)$$

Свернем обратно $\hat{Y}(x)$

$$\nabla MSE = \left(-2\frac{\sum_{i=1}^n{\left(Y_i - \hat{Y}\right)}}{n}, -2\frac{\sum_{i=1}^n{\left(Y_i - \hat{Y}\right)x_i}}{n} \right)$$

Изменяем коэффициенты $a_0$ и $a_1$, тем самым минимизируя функцию потерь

$$a_0^{(t+1)} = a_0^{(t)} - \nabla(MSE)_0$$

$$a_1^{(t+1)} = a_1^{(t)} - \nabla(MSE)_1$$


## Multiple Linear Regression

Функция, описывающая зависимость целевой переменной от N параметров.

$$Y(x_1, x_2, ..., x_n) = a_0 + a_1x_1 + a_2x_2 + ... + a_nx_n + \alpha$$

В матричном виде 

$$y = X@A + \alpha$$

Функция, которая пытается оценить значение целевой переменной по N параметрам.

$$\hat{Y}(x_1, x_2, ..., x_n) = a_0 + a_1x_1 + a_2x_2 + ... + a_nx_n$$

В матричном виде

$$\hat{y} = X@A$$

Суть регрессии не меняется, мы пытаемся минимизировать функцию потерь соответственно минимизировать ошибки в предсказаниях.

Функция MSE в матричной форме

$$MSE (Mean Square Error)  = \frac{\sum_{i=1}^n{\left(Y_i - x_i @ A\right)^2}}{n} \rArr min$$

- $@$ - матричное умножение (как в numpy)
- $Y_i$ - $i$ результат функции $Y$
- $A$ - вертикальный вектор из коэффициентов $a$ в функции $\hat{Y}(x)$
- $x_i$ - строка из $X$ значений в функции $\hat{Y}(x)$

Ищем градиент по $A$ переменным.

Записываем все в матричной форме для удобства

$$MSE = \frac{1}{n}(Y-X@A)^T(Y-X@A)$$

Вычисляем наблу.

$$\nabla MSE = \frac{2}{n}(-X)^T(Y-X@A)$$

Вынесем, что выносится, получаем

$$\nabla MSE = -\frac{2}{n}X^T(Y-X@A)$$

Сама регрессия будет считаться так:

Изменяем коэффициенты $A$, тем самым минимизируя функцию потерь.

$$A_{начальные} = случайные числа.$$

$$A^{(t+1)} = A^{(t)} - \nabla(A^{(t)}) + \alpha$$

Еще формулы

Вектор оценок коэффициентов линейной регрессии.
Это математическая формула для получения значений $\hat{A}$. 
Полученные таким методом коэффициенты будут иметь очень большую накопительную ошибку из-за вычисления детерминанта. Гораздо точнее будет итеративно улучшать коэффициенты.

$$\hat{A} = (X^{T}X)^{(-1)}X^{T}Y$$

---

Суть проиходящего в том, что  мы пытаемся найти сумму квадратов отклонений аппроксимируемой функции от эксперементальных данных, потом мы ищем от этого градиент, чтобы это все минимизировать движемся по градиенту обратно, смещая коэффициенты. в качестве начальных значений мы выбираем случайные числа.

## Оценка качества модели

Точность предсказания оценивается при помощи таких функций как:

- [[organize.resource.data-mining.mae|mae]]
- [[organize.resource.data-mining.mape|mape]]

В некоторых библиотеках и материалах используется [[organize.resource.data-mining.coefficient-of-determination|coefficient of determination]] для оценки качества ошибки, но ее сложно интерпретировать, поэтому лучше использовать MAE.